{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the pdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIGITAL NOTES \n",
      "ON \n",
      "JAVA PROGRAMMING (R20A0508) \n",
      " \n",
      "\n",
      "Extraction complete\n"
     ]
    }
   ],
   "source": [
    "import fitz \n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    \n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)  \n",
    "        text += page.get_text()  \n",
    "    return text\n",
    "\n",
    "\n",
    "pdf_path = \"JAVA_PROGRAMMING.pdf\" \n",
    "pdf_text = extract_text_from_pdf(pdf_path)\n",
    "print(pdf_text[:50])\n",
    "\n",
    "print(\"Extraction complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question 1:\n",
      "Select Bloom's Taxonomy level(s) for this question:\n",
      "1. Remember\n",
      "2. Understand\n",
      "3. Apply\n",
      "4. Analyze\n",
      "5. Evaluate\n",
      "6. Create\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (5287 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question 2:\n",
      "Select Bloom's Taxonomy level(s) for this question:\n",
      "1. Remember\n",
      "2. Understand\n",
      "3. Apply\n",
      "4. Analyze\n",
      "5. Evaluate\n",
      "6. Create\n",
      "\n",
      "Question 3:\n",
      "Select Bloom's Taxonomy level(s) for this question:\n",
      "1. Remember\n",
      "2. Understand\n",
      "3. Apply\n",
      "4. Analyze\n",
      "5. Evaluate\n",
      "6. Create\n",
      "\n",
      "Question 4:\n",
      "Select Bloom's Taxonomy level(s) for this question:\n",
      "1. Remember\n",
      "2. Understand\n",
      "3. Apply\n",
      "4. Analyze\n",
      "5. Evaluate\n",
      "6. Create\n",
      "\n",
      "Question 5:\n",
      "Select Bloom's Taxonomy level(s) for this question:\n",
      "1. Remember\n",
      "2. Understand\n",
      "3. Apply\n",
      "4. Analyze\n",
      "5. Evaluate\n",
      "6. Create\n",
      "\n",
      "PDF generated as 'question_paper.pdf'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from reportlab.lib import colors\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.units import inch\n",
    "from reportlab.pdfgen import canvas\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Loading the fine-tuned model\n",
    "model_path = \"./flan-t5-base-finetuned\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_path).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "BLOOM_LEVELS = {\n",
    "    1: \"Remember\",\n",
    "    2: \"Understand\",\n",
    "    3: \"Apply\",\n",
    "    4: \"Analyze\",\n",
    "    5: \"Evaluate\",\n",
    "    6: \"Create\"\n",
    "}\n",
    "\n",
    "def generate_question(context, bloom_levels, max_length=50):\n",
    "    level_prompts = [f\"{BLOOM_LEVELS[level]} level\" for level in bloom_levels]\n",
    "    level_prompt = \" and \".join(level_prompts)\n",
    "    prompt = f\"Generate a {level_prompt} question based on this text: {context}\"\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "    outputs = model.generate(input_ids, max_length=max_length, num_return_sequences=1, \n",
    "                             do_sample=True, temperature=0.7, top_k=50)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "def get_bloom_levels():\n",
    "    print(\"Select Bloom's Taxonomy level(s) for this question:\")\n",
    "    for key, value in BLOOM_LEVELS.items():\n",
    "        print(f\"{key}. {value}\")\n",
    "    levels = input(\"Enter the numbers of the desired levels (comma-separated): \")\n",
    "    return [int(level.strip()) for level in levels.split(',')]\n",
    "\n",
    "def generate_test(num_questions=5, context_length=20000):\n",
    "    test_questions = []\n",
    "    \n",
    "    \n",
    "    for i in range(num_questions):\n",
    "        print(f\"\\nQuestion {i+1}:\")\n",
    "        bloom_levels = get_bloom_levels()\n",
    "        \n",
    "        start = torch.randint(0, max(1, len(pdf_text) - context_length), (1,)).item()\n",
    "        context = pdf_text[start:start+context_length]\n",
    "        \n",
    "        question = generate_question(context, bloom_levels)\n",
    "        test_questions.append((question, bloom_levels))\n",
    "    \n",
    "    return test_questions\n",
    "\n",
    "\n",
    "from reportlab.lib import colors\n",
    "from reportlab.lib.pagesizes import letter, inch\n",
    "from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer, Image\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.units import mm\n",
    "\n",
    "def create_pdf(questions, subject, year, ia_number):\n",
    "    doc = SimpleDocTemplate(\"question_paper.pdf\", pagesize=letter, topMargin=0.5*inch, bottomMargin=0.5*inch, leftMargin=0.5*inch, rightMargin=0.5*inch)\n",
    "    styles = getSampleStyleSheet()\n",
    "    elements = []\n",
    "\n",
    "   \n",
    "    logo = Image('university_logo.png', width=50*mm, height=25*mm)\n",
    "    elements.append(logo)\n",
    "    elements.append(Spacer(1, 0.2*inch))\n",
    "\n",
    "  \n",
    "    info_style = ParagraphStyle(name='Info', fontSize=14, alignment=1, spaceAfter=10)\n",
    "    info = Paragraph(f\"{subject}<br/>Year: {year}<br/>IA {ia_number}\", info_style)\n",
    "    elements.append(info)\n",
    "    elements.append(Spacer(1, 0.2*inch))\n",
    "\n",
    " \n",
    "    data = [['SL.\\nNo.', 'Question', 'Marks', \"Bloom's\\nLevel\"]]\n",
    "    for i, (question, levels) in enumerate(questions, 1):\n",
    "        level_names = [BLOOM_LEVELS[level] for level in levels]\n",
    "       \n",
    "        wrapped_question = Paragraph(question, styles['Normal'])\n",
    "        data.append([str(i), wrapped_question, '10', ', '.join(level_names)])\n",
    "\n",
    "   \n",
    "    table = Table(data, colWidths=[0.6*inch, 4.3*inch, 0.6*inch, 1.5*inch])\n",
    "    table.setStyle(TableStyle([\n",
    "        ('BACKGROUND', (0,0), (-1,0), colors.grey),\n",
    "        ('TEXTCOLOR', (0,0), (-1,0), colors.whitesmoke),\n",
    "        ('ALIGN', (0,0), (-1,-1), 'CENTER'),\n",
    "        ('VALIGN', (0,0), (-1,-1), 'MIDDLE'),\n",
    "        ('FONTNAME', (0,0), (-1,0), 'Helvetica-Bold'),\n",
    "        ('FONTSIZE', (0,0), (-1,0), 12),\n",
    "        ('BOTTOMPADDING', (0,0), (-1,0), 12),\n",
    "        ('BACKGROUND', (0,1), (-1,-1), colors.beige),\n",
    "        ('TEXTCOLOR', (0,1), (-1,-1), colors.black),\n",
    "        ('ALIGN', (1,1), (1,-1), 'LEFT'), \n",
    "        ('FONTNAME', (0,1), (-1,-1), 'Helvetica'),\n",
    "        ('FONTSIZE', (0,1), (-1,-1), 10),\n",
    "        ('TOPPADDING', (0,1), (-1,-1), 12),  \n",
    "        ('BOTTOMPADDING', (0,1), (-1,-1), 12), \n",
    "        ('GRID', (0,0), (-1,-1), 1, colors.black),\n",
    "        ('WORDWRAP', (0,0), (-1,-1)),  \n",
    "    ]))\n",
    "    elements.append(table)\n",
    "\n",
    "    doc.build(elements)\n",
    "\n",
    "\n",
    "subject = input(\"Enter the subject name: \")\n",
    "year = input(\"Enter the year: \")\n",
    "ia_number = input(\"Enter the IA number: \")\n",
    "\n",
    "\n",
    "test = generate_test(num_questions=5)\n",
    "\n",
    "\n",
    "create_pdf(test, subject, year, ia_number)\n",
    "\n",
    "print(\"\\nPDF generated as 'question_paper.pdf'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
